"""
Repository Connectors for External System Integration
Supports Git, Confluence, SharePoint, Jira, and other systems
"""

import asyncio
import json
import os
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional
import aiohttp
import aiofiles
from datetime import datetime

class RepositoryConnector(ABC):
    """Abstract base class for repository connectors"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.name = config.get("name", "Unknown")
        self.base_url = config.get("base_url", "")
        self.auth_config = config.get("authentication", {})
    
    @abstractmethod
    async def store_artifacts(
        self, 
        artifacts: List[Dict[str, Any]], 
        config: Dict[str, Any],
        context: Any
    ) -> Dict[str, Any]:
        """Store artifacts in the repository"""
        pass
    
    @abstractmethod
    async def retrieve_artifacts(
        self, 
        query: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Retrieve artifacts from the repository"""
        pass
    
    @abstractmethod
    async def validate_connection(self) -> bool:
        """Validate connection to the repository"""
        pass

class GitRepositoryConnector(RepositoryConnector):
    """Connector for Git repositories (GitHub, GitLab, Bitbucket)"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.git_provider = config.get("provider", "github")  # github, gitlab, bitbucket
        self.repository = config.get("repository", "")
        self.branch = config.get("branch", "main")
        self.token = config.get("token", "")
    
    async def store_artifacts(
        self, 
        artifacts: List[Dict[str, Any]], 
        config: Dict[str, Any],
        context: Any
    ) -> Dict[str, Any]:
        """Store code artifacts in Git repository"""
        
        stored_files = []
        
        for artifact in artifacts:
            try:
                # Determine file path based on artifact type
                file_path = self._get_file_path(artifact, config)
                
                # Create or update file in repository
                result = await self._create_or_update_file(
                    file_path=file_path,
                    content=artifact["content"],
                    message=f"Generated by SDLC Pipeline - {artifact['name']}",
                    artifact=artifact
                )
                
                stored_files.append({
                    "artifact_name": artifact["name"],
                    "file_path": file_path,
                    "commit_sha": result.get("commit_sha"),
                    "url": result.get("html_url"),
                    "status": "success"
                })
                
            except Exception as e:
                stored_files.append({
                    "artifact_name": artifact["name"],
                    "status": "failed",
                    "error": str(e)
                })
        
        return {
            "repository": self.repository,
            "branch": self.branch,
            "stored_files": stored_files,
            "total_files": len(stored_files),
            "success_count": len([f for f in stored_files if f["status"] == "success"])
        }
    
    def _get_file_path(self, artifact: Dict[str, Any], config: Dict[str, Any]) -> str:
        """Determine file path based on artifact type and configuration"""
        
        base_path = config.get("base_path", "")
        artifact_type = artifact.get("type", "unknown")
        
        # Define path patterns for different artifact types
        path_patterns = {
            "source_code": "src/main/java/{package_path}/{class_name}.java",
            "test_code": "src/test/java/{package_path}/{class_name}Test.java",
            "documentation": "docs/{artifact_name}.md",
            "configuration": "config/{artifact_name}",
            "docker": "docker/{artifact_name}",
            "kubernetes": "k8s/{artifact_name}.yaml",
            "pipeline": ".github/workflows/{artifact_name}.yml"
        }
        
        pattern = path_patterns.get(artifact_type, "{artifact_name}")
        
        # Replace placeholders
        file_path = pattern.format(
            artifact_name=artifact["name"],
            package_path=artifact.get("package", "").replace(".", "/"),
            class_name=artifact.get("class_name", artifact["name"])
        )
        
        return os.path.join(base_path, file_path).replace("\\", "/")
    
    async def _create_or_update_file(
        self, 
        file_path: str, 
        content: str, 
        message: str,
        artifact: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Create or update a file in the Git repository"""
        
        headers = {
            "Authorization": f"token {self.token}",
            "Accept": "application/vnd.github.v3+json"
        }
        
        # GitHub API endpoint
        if self.git_provider == "github":
            api_url = f"https://api.github.com/repos/{self.repository}/contents/{file_path}"
        elif self.git_provider == "gitlab":
            api_url = f"https://gitlab.com/api/v4/projects/{self.repository.replace('/', '%2F')}/repository/files/{file_path.replace('/', '%2F')}"
        else:
            raise ValueError(f"Unsupported Git provider: {self.git_provider}")
        
        async with aiohttp.ClientSession() as session:
            # Check if file exists
            async with session.get(api_url, headers=headers) as response:
                file_exists = response.status == 200
                existing_sha = None
                
                if file_exists:
                    file_data = await response.json()
                    existing_sha = file_data.get("sha")
            
            # Prepare request data
            request_data = {
                "message": message,
                "content": self._encode_content(content),
                "branch": self.branch
            }
            
            if file_exists and existing_sha:
                request_data["sha"] = existing_sha
            
            # Create or update file
            async with session.put(api_url, headers=headers, json=request_data) as response:
                if response.status in [200, 201]:
                    result = await response.json()
                    return {
                        "commit_sha": result.get("commit", {}).get("sha"),
                        "html_url": result.get("content", {}).get("html_url"),
                        "download_url": result.get("content", {}).get("download_url")
                    }
                else:
                    error_text = await response.text()
                    raise Exception(f"Failed to store file in Git: {response.status} - {error_text}")
    
    def _encode_content(self, content: str) -> str:
        """Encode content for Git API"""
        import base64
        return base64.b64encode(content.encode('utf-8')).decode('utf-8')
    
    async def retrieve_artifacts(self, query: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Retrieve artifacts from Git repository"""
        # Implementation for retrieving files from Git
        pass
    
    async def validate_connection(self) -> bool:
        """Validate connection to Git repository"""
        headers = {"Authorization": f"token {self.token}"}
        api_url = f"https://api.github.com/repos/{self.repository}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(api_url, headers=headers) as response:
                return response.status == 200

class ConfluenceConnector(RepositoryConnector):
    """Connector for Atlassian Confluence"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.space_key = config.get("space_key", "")
        self.username = config.get("username", "")
        self.api_token = config.get("api_token", "")
    
    async def store_artifacts(
        self, 
        artifacts: List[Dict[str, Any]], 
        config: Dict[str, Any],
        context: Any
    ) -> Dict[str, Any]:
        """Store documentation artifacts in Confluence"""
        
        stored_pages = []
        
        for artifact in artifacts:
            try:
                page_title = artifact["name"]
                page_content = self._convert_to_confluence_format(artifact["content"])
                
                # Create or update Confluence page
                result = await self._create_or_update_page(
                    title=page_title,
                    content=page_content,
                    artifact=artifact
                )
                
                stored_pages.append({
                    "artifact_name": artifact["name"],
                    "page_id": result.get("id"),
                    "page_url": result.get("_links", {}).get("webui"),
                    "status": "success"
                })
                
            except Exception as e:
                stored_pages.append({
                    "artifact_name": artifact["name"],
                    "status": "failed",
                    "error": str(e)
                })
        
        return {
            "space_key": self.space_key,
            "stored_pages": stored_pages,
            "total_pages": len(stored_pages),
            "success_count": len([p for p in stored_pages if p["status"] == "success"])
        }
    
    def _convert_to_confluence_format(self, content: str) -> str:
        """Convert markdown content to Confluence storage format"""
        
        # Basic conversion from Markdown to Confluence
        # In production, use a proper Markdown to Confluence converter
        
        confluence_content = content
        
        # Convert headers
        confluence_content = confluence_content.replace("# ", "<h1>")
        confluence_content = confluence_content.replace("## ", "<h2>")
        confluence_content = confluence_content.replace("### ", "<h3>")
        
        # Convert code blocks
        confluence_content = confluence_content.replace("```", "<ac:structured-macro ac:name=\"code\"><ac:plain-text-body><![CDATA[")
        confluence_content = confluence_content.replace("```", "]]></ac:plain-text-body></ac:structured-macro>")
        
        # Convert tables (basic implementation)
        # More sophisticated conversion would be needed for production
        
        return confluence_content
    
    async def _create_or_update_page(
        self, 
        title: str, 
        content: str, 
        artifact: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Create or update a Confluence page"""
        
        auth = aiohttp.BasicAuth(self.username, self.api_token)
        headers = {"Content-Type": "application/json"}
        
        # Check if page exists
        search_url = f"{self.base_url}/rest/api/content"
        params = {
            "title": title,
            "spaceKey": self.space_key,
            "expand": "version"
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(search_url, params=params, auth=auth, headers=headers) as response:
                search_result = await response.json()
                
                page_exists = len(search_result.get("results", [])) > 0
                
                if page_exists:
                    # Update existing page
                    existing_page = search_result["results"][0]
                    page_id = existing_page["id"]
                    current_version = existing_page["version"]["number"]
                    
                    update_url = f"{self.base_url}/rest/api/content/{page_id}"
                    update_data = {
                        "version": {"number": current_version + 1},
                        "title": title,
                        "type": "page",
                        "body": {
                            "storage": {
                                "value": content,
                                "representation": "storage"
                            }
                        }
                    }
                    
                    async with session.put(update_url, json=update_data, auth=auth, headers=headers) as response:
                        if response.status == 200:
                            return await response.json()
                        else:
                            error_text = await response.text()
                            raise Exception(f"Failed to update Confluence page: {response.status} - {error_text}")
                
                else:
                    # Create new page
                    create_url = f"{self.base_url}/rest/api/content"
                    create_data = {
                        "type": "page",
                        "title": title,
                        "space": {"key": self.space_key},
                        "body": {
                            "storage": {
                                "value": content,
                                "representation": "storage"
                            }
                        }
                    }
                    
                    async with session.post(create_url, json=create_data, auth=auth, headers=headers) as response:
                        if response.status == 200:
                            return await response.json()
                        else:
                            error_text = await response.text()
                            raise Exception(f"Failed to create Confluence page: {response.status} - {error_text}")
    
    async def retrieve_artifacts(self, query: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Retrieve pages from Confluence"""
        # Implementation for retrieving Confluence pages
        pass
    
    async def validate_connection(self) -> bool:
        """Validate connection to Confluence"""
        auth = aiohttp.BasicAuth(self.username, self.api_token)
        test_url = f"{self.base_url}/rest/api/space/{self.space_key}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(test_url, auth=auth) as response:
                return response.status == 200

class SharePointConnector(RepositoryConnector):
    """Connector for Microsoft SharePoint"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.site_id = config.get("site_id", "")
        self.library_name = config.get("library_name", "Documents")
        self.tenant_id = config.get("tenant_id", "")
        self.client_id = config.get("client_id", "")
        self.client_secret = config.get("client_secret", "")
        self.access_token = None
    
    async def store_artifacts(
        self, 
        artifacts: List[Dict[str, Any]], 
        config: Dict[str, Any],
        context: Any
    ) -> Dict[str, Any]:
        """Store artifacts in SharePoint document library"""
        
        # Ensure we have an access token
        await self._ensure_access_token()
        
        stored_documents = []
        
        for artifact in artifacts:
            try:
                file_name = f"{artifact['name']}.{self._get_file_extension(artifact['type'])}"
                folder_path = config.get("folder_path", "SDLC Pipeline")
                
                # Upload file to SharePoint
                result = await self._upload_file(
                    file_name=file_name,
                    content=artifact["content"],
                    folder_path=folder_path,
                    artifact=artifact
                )
                
                stored_documents.append({
                    "artifact_name": artifact["name"],
                    "file_name": file_name,
                    "file_id": result.get("id"),
                    "web_url": result.get("webUrl"),
                    "status": "success"
                })
                
            except Exception as e:
                stored_documents.append({
                    "artifact_name": artifact["name"],
                    "status": "failed",
                    "error": str(e)
                })
        
        return {
            "site_id": self.site_id,
            "library_name": self.library_name,
            "stored_documents": stored_documents,
            "total_documents": len(stored_documents),
            "success_count": len([d for d in stored_documents if d["status"] == "success"])
        }
    
    async def _ensure_access_token(self):
        """Ensure we have a valid access token"""
        
        if self.access_token:
            # In production, check token expiration
            return
        
        # Get access token using client credentials flow
        token_url = f"https://login.microsoftonline.com/{self.tenant_id}/oauth2/v2.0/token"
        
        data = {
            "grant_type": "client_credentials",
            "client_id": self.client_id,
            "client_secret": self.client_secret,
            "scope": "https://graph.microsoft.com/.default"
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(token_url, data=data) as response:
                if response.status == 200:
                    token_data = await response.json()
                    self.access_token = token_data["access_token"]
                else:
                    error_text = await response.text()
                    raise Exception(f"Failed to get SharePoint access token: {response.status} - {error_text}")
    
    async def _upload_file(
        self, 
        file_name: str, 
        content: str, 
        folder_path: str, 
        artifact: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Upload a file to SharePoint"""
        
        headers = {
            "Authorization": f"Bearer {self.access_token}",
            "Content-Type": "application/json"
        }
        
        # Create folder if it doesn't exist
        await self._ensure_folder_exists(folder_path, headers)
        
        # Upload file
        upload_url = f"https://graph.microsoft.com/v1.0/sites/{self.site_id}/drive/root:/{folder_path}/{file_name}:/content"
        
        async with aiohttp.ClientSession() as session:
            async with session.put(upload_url, data=content.encode('utf-8'), headers={
                "Authorization": f"Bearer {self.access_token}",
                "Content-Type": "text/plain"
            }) as response:
                if response.status in [200, 201]:
                    return await response.json()
                else:
                    error_text = await response.text()
                    raise Exception(f"Failed to upload file to SharePoint: {response.status} - {error_text}")
    
    async def _ensure_folder_exists(self, folder_path: str, headers: Dict[str, str]):
        """Ensure the folder exists in SharePoint"""
        
        folder_url = f"https://graph.microsoft.com/v1.0/sites/{self.site_id}/drive/root:/{folder_path}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(folder_url, headers=headers) as response:
                if response.status == 404:
                    # Create folder
                    create_data = {
                        "name": folder_path.split("/")[-1],
                        "folder": {}
                    }
                    
                    parent_path = "/".join(folder_path.split("/")[:-1]) if "/" in folder_path else ""
                    create_url = f"https://graph.microsoft.com/v1.0/sites/{self.site_id}/drive/root:/{parent_path}:/children" if parent_path else f"https://graph.microsoft.com/v1.0/sites/{self.site_id}/drive/root/children"
                    
                    async with session.post(create_url, json=create_data, headers=headers) as create_response:
                        if create_response.status not in [200, 201]:
                            error_text = await create_response.text()
                            raise Exception(f"Failed to create SharePoint folder: {create_response.status} - {error_text}")
    
    def _get_file_extension(self, artifact_type: str) -> str:
        """Get appropriate file extension based on artifact type"""
        
        extensions = {
            "documentation": "md",
            "requirements": "md",
            "design": "md",
            "test_plan": "md",
            "runbook": "md",
            "source_code": "java",
            "configuration": "yml",
            "script": "sh"
        }
        
        return extensions.get(artifact_type, "txt")
    
    async def retrieve_artifacts(self, query: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Retrieve documents from SharePoint"""
        # Implementation for retrieving SharePoint documents
        pass
    
    async def validate_connection(self) -> bool:
        """Validate connection to SharePoint"""
        try:
            await self._ensure_access_token()
            
            headers = {"Authorization": f"Bearer {self.access_token}"}
            test_url = f"https://graph.microsoft.com/v1.0/sites/{self.site_id}"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(test_url, headers=headers) as response:
                    return response.status == 200
        except:
            return False

class JiraConnector(RepositoryConnector):
    """Connector for Atlassian Jira"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.project_key = config.get("project_key", "")
        self.username = config.get("username", "")
        self.api_token = config.get("api_token", "")
    
    async def store_artifacts(
        self, 
        artifacts: List[Dict[str, Any]], 
        config: Dict[str, Any],
        context: Any
    ) -> Dict[str, Any]:
        """Store artifacts as Jira issues or attachments"""
        
        created_issues = []
        
        for artifact in artifacts:
            try:
                # Create Jira issue based on artifact
                issue_data = self._prepare_issue_data(artifact, config)
                
                result = await self._create_issue(issue_data)
                
                created_issues.append({
                    "artifact_name": artifact["name"],
                    "issue_key": result.get("key"),
                    "issue_id": result.get("id"),
                    "issue_url": f"{self.base_url}/browse/{result.get('key')}",
                    "status": "success"
                })
                
            except Exception as e:
                created_issues.append({
                    "artifact_name": artifact["name"],
                    "status": "failed",
                    "error": str(e)
                })
        
        return {
            "project_key": self.project_key,
            "created_issues": created_issues,
            "total_issues": len(created_issues),
            "success_count": len([i for i in created_issues if i["status"] == "success"])
        }
    
    def _prepare_issue_data(self, artifact: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """Prepare Jira issue data from artifact"""
        
        issue_type_mapping = {
            "requirements": "Story",
            "test_plan": "Test",
            "bug_report": "Bug",
            "task": "Task"
        }
        
        issue_type = issue_type_mapping.get(artifact.get("type"), "Task")
        
        return {
            "fields": {
                "project": {"key": self.project_key},
                "summary": artifact["name"],
                "description": artifact["content"][:32000],  # Jira has character limits
                "issuetype": {"name": issue_type},
                "labels": ["sdlc-pipeline", artifact.get("type", "generated")]
            }
        }
    
    async def _create_issue(self, issue_data: Dict[str, Any]) -> Dict[str, Any]:
        """Create a Jira issue"""
        
        auth = aiohttp.BasicAuth(self.username, self.api_token)
        headers = {"Content-Type": "application/json"}
        
        create_url = f"{self.base_url}/rest/api/2/issue"
        
        async with aiohttp.ClientSession() as session:
            async with session.post(create_url, json=issue_data, auth=auth, headers=headers) as response:
                if response.status == 201:
                    return await response.json()
                else:
                    error_text = await response.text()
                    raise Exception(f"Failed to create Jira issue: {response.status} - {error_text}")
    
    async def retrieve_artifacts(self, query: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Retrieve issues from Jira"""
        # Implementation for retrieving Jira issues
        pass
    
    async def validate_connection(self) -> bool:
        """Validate connection to Jira"""
        auth = aiohttp.BasicAuth(self.username, self.api_token)
        test_url = f"{self.base_url}/rest/api/2/project/{self.project_key}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(test_url, auth=auth) as response:
                return response.status == 200

class RepositoryConnectorFactory:
    """Factory for creating repository connectors"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.connectors = {}
    
    def get_connector(self, connector_type: str) -> RepositoryConnector:
        """Get a connector instance for the specified type"""
        
        if connector_type in self.connectors:
            return self.connectors[connector_type]
        
        connector_config = self.config.get(connector_type, {})
        
        if connector_type == "git":
            connector = GitRepositoryConnector(connector_config)
        elif connector_type == "confluence":
            connector = ConfluenceConnector(connector_config)
        elif connector_type == "sharepoint":
            connector = SharePointConnector(connector_config)
        elif connector_type == "jira":
            connector = JiraConnector(connector_config)
        else:
            raise ValueError(f"Unknown connector type: {connector_type}")
        
        self.connectors[connector_type] = connector
        return connector
    
    async def validate_all_connections(self) -> Dict[str, bool]:
        """Validate connections for all configured connectors"""
        
        results = {}
        
        for connector_type in self.config.keys():
            try:
                connector = self.get_connector(connector_type)
                results[connector_type] = await connector.validate_connection()
            except Exception as e:
                results[connector_type] = False
        
        return results
